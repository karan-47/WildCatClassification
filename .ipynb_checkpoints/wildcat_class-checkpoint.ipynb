{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4709a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/sankettangade/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - opencv\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    boltons-23.0.0             |  py310hecd8cb5_0         426 KB\n",
      "    cairo-1.16.0               |       h3ce6f7e_4        1011 KB\n",
      "    conda-23.3.1               |  py310hecd8cb5_0         973 KB\n",
      "    eigen-3.3.7                |       haf03e11_1         832 KB\n",
      "    expat-2.4.9                |       he9d5cce_0         127 KB\n",
      "    ffmpeg-4.2.2               |       h97e5cf8_0        22.9 MB\n",
      "    fontconfig-2.14.1          |       hedf32ac_1         249 KB\n",
      "    gnutls-3.6.15              |       hed9c0bf_0         974 KB\n",
      "    graphite2-1.3.14           |       he9d5cce_1          82 KB\n",
      "    harfbuzz-4.3.0             |       hffc734d_1         1.2 MB\n",
      "    jsonpatch-1.32             |     pyhd3eb1b0_0          15 KB\n",
      "    jsonpointer-2.1            |     pyhd3eb1b0_0           9 KB\n",
      "    lame-3.100                 |       h1de35cc_0         316 KB\n",
      "    libidn2-2.3.2              |       h9ed2024_0          85 KB\n",
      "    libopus-1.3.1              |       h1de35cc_0         480 KB\n",
      "    libtasn1-4.19.0            |       h6c40b1e_0          67 KB\n",
      "    libunistring-0.9.10        |       h9ed2024_0         519 KB\n",
      "    libvpx-1.7.0               |       h378b8a2_0         1.3 MB\n",
      "    nettle-3.7.3               |       h230ac6f_1         380 KB\n",
      "    opencv-4.6.0               |  py310h3ea8b11_3        26.0 MB\n",
      "    openh264-2.1.1             |       h8346a28_0         655 KB\n",
      "    pixman-0.40.0              |       h9ed2024_1         341 KB\n",
      "    x264-1!157.20191217        |       h1de35cc_0         910 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        59.6 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  boltons            pkgs/main/osx-64::boltons-23.0.0-py310hecd8cb5_0 \n",
      "  cairo              pkgs/main/osx-64::cairo-1.16.0-h3ce6f7e_4 \n",
      "  eigen              pkgs/main/osx-64::eigen-3.3.7-haf03e11_1 \n",
      "  expat              pkgs/main/osx-64::expat-2.4.9-he9d5cce_0 \n",
      "  ffmpeg             pkgs/main/osx-64::ffmpeg-4.2.2-h97e5cf8_0 \n",
      "  fontconfig         pkgs/main/osx-64::fontconfig-2.14.1-hedf32ac_1 \n",
      "  gnutls             pkgs/main/osx-64::gnutls-3.6.15-hed9c0bf_0 \n",
      "  graphite2          pkgs/main/osx-64::graphite2-1.3.14-he9d5cce_1 \n",
      "  harfbuzz           pkgs/main/osx-64::harfbuzz-4.3.0-hffc734d_1 \n",
      "  jsonpatch          pkgs/main/noarch::jsonpatch-1.32-pyhd3eb1b0_0 \n",
      "  jsonpointer        pkgs/main/noarch::jsonpointer-2.1-pyhd3eb1b0_0 \n",
      "  lame               pkgs/main/osx-64::lame-3.100-h1de35cc_0 \n",
      "  libidn2            pkgs/main/osx-64::libidn2-2.3.2-h9ed2024_0 \n",
      "  libopus            pkgs/main/osx-64::libopus-1.3.1-h1de35cc_0 \n",
      "  libtasn1           pkgs/main/osx-64::libtasn1-4.19.0-h6c40b1e_0 \n",
      "  libunistring       pkgs/main/osx-64::libunistring-0.9.10-h9ed2024_0 \n",
      "  libvpx             pkgs/main/osx-64::libvpx-1.7.0-h378b8a2_0 \n",
      "  nettle             pkgs/main/osx-64::nettle-3.7.3-h230ac6f_1 \n",
      "  opencv             pkgs/main/osx-64::opencv-4.6.0-py310h3ea8b11_3 \n",
      "  openh264           pkgs/main/osx-64::openh264-2.1.1-h8346a28_0 \n",
      "  pixman             pkgs/main/osx-64::pixman-0.40.0-h9ed2024_1 \n",
      "  x264               pkgs/main/osx-64::x264-1!157.20191217-h1de35cc_0 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda                              23.1.0-py310hecd8cb5_0 --> 23.3.1-py310hecd8cb5_0 \n",
      "\n",
      "\n",
      "Proceed ([y]/n)? "
     ]
    }
   ],
   "source": [
    "!conda install opencv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "448cc898",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class_names = sorted(os.listdir(\"train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4f8ce85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AFRICAN LEOPARD',\n",
       " 'CARACAL',\n",
       " 'CHEETAH',\n",
       " 'CLOUDED LEOPARD',\n",
       " 'JAGUAR',\n",
       " 'LIONS',\n",
       " 'OCELOT',\n",
       " 'PUMA',\n",
       " 'SNOW LEOPARD',\n",
       " 'TIGER']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f94852ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    class_dir = os.path.join(\"train\", class_name)\n",
    "    for filename in os.listdir(class_dir):\n",
    "        # Load the image and convert it to a numpy array\n",
    "        img = cv2.imread(os.path.join(class_dir, filename))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_array = np.array(img)\n",
    "\n",
    "        # Append the numpy array to x_train\n",
    "        x_train.append(img_array)\n",
    "\n",
    "        # Append the corresponding label to y_train\n",
    "        y_train.append(i)\n",
    "\n",
    "# Convert x_train and y_train to numpy arrays\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "67069af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fef93e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {i: class_names[i] for i in range(len(class_names))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b89b5437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0db62762",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = []\n",
    "y_val = []\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    class_dir = os.path.join(\"valid\", class_name)\n",
    "    for filename in os.listdir(class_dir):\n",
    "        # Load the image and convert it to a numpy array\n",
    "        img = cv2.imread(os.path.join(class_dir, filename))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_array = np.array(img)\n",
    "\n",
    "        # Append the numpy array to x_train\n",
    "        x_val.append(img_array)\n",
    "\n",
    "        # Append the corresponding label to y_train\n",
    "        y_val.append(i)\n",
    "\n",
    "# Convert x_train and y_train to numpy arrays\n",
    "x_val = np.array(x_val)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476bf531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ce8ccec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "y_val = to_categorical(y_val, num_classes=10)\n",
    "print(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "299ac629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train_new: (1911, 224, 224, 3)\n",
      "Shape of y_train_new: (1911, 10)\n",
      "Shape of x_test_new: (478, 224, 224, 3)\n",
      "Shape of y_test_new: (478, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Concatenate the x and y arrays\n",
    "x_all = np.concatenate([x_train, x_val], axis=0)\n",
    "y_all = np.concatenate([y_train, y_val], axis=0)\n",
    "\n",
    "# Create a StratifiedShuffleSplit object\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use the StratifiedShuffleSplit object to split the data\n",
    "train_indices, test_indices = next(sss.split(x_all, y_all))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train_new, x_test_new = x_all[train_indices], x_all[test_indices]\n",
    "y_train_new, y_test_new = y_all[train_indices], y_all[test_indices]\n",
    "\n",
    "# Verify the shapes of the new arrays\n",
    "print(f'Shape of x_train_new: {x_train_new.shape}')\n",
    "print(f'Shape of y_train_new: {y_train_new.shape}')\n",
    "print(f'Shape of x_test_new: {x_test_new.shape}')\n",
    "print(f'Shape of y_test_new: {y_test_new.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "78d8f725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "60/60 [==============================] - 297s 5s/step - loss: 12.3146 - accuracy: 0.6154 - val_loss: 2.3101 - val_accuracy: 0.7615\n",
      "Epoch 2/6\n",
      "60/60 [==============================] - 313s 5s/step - loss: 0.5451 - accuracy: 0.9278 - val_loss: 1.2948 - val_accuracy: 0.8494\n",
      "Epoch 3/6\n",
      "60/60 [==============================] - 296s 5s/step - loss: 0.1663 - accuracy: 0.9702 - val_loss: 1.7123 - val_accuracy: 0.8347\n",
      "Epoch 4/6\n",
      "60/60 [==============================] - 329s 6s/step - loss: 0.2319 - accuracy: 0.9712 - val_loss: 1.4900 - val_accuracy: 0.8598\n",
      "Epoch 5/6\n",
      "60/60 [==============================] - 317s 5s/step - loss: 0.1161 - accuracy: 0.9796 - val_loss: 1.2487 - val_accuracy: 0.8891\n",
      "Epoch 6/6\n",
      "60/60 [==============================] - 311s 5s/step - loss: 0.0644 - accuracy: 0.9864 - val_loss: 1.6105 - val_accuracy: 0.8389\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load the pre-trained ResNet50 model\n",
    "resnet_model = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "# Freeze the layers in the pre-trained model\n",
    "for layer in resnet_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add your own classification layers\n",
    "x = Flatten()(resnet_model.output)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Create the new model\n",
    "model = Model(inputs=resnet_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model with a lower learning rate\n",
    "opt = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model with validation data\n",
    "history = model.fit(x_train_new, y_train_new, epochs=6, batch_size=32, validation_data=(x_test_new, y_test_new))\n",
    "\n",
    "# Save the model\n",
    "model.save(\"Models/resnet50.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40c160a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60/60 [==============================] - 274s 5s/step - loss: 1.5057 - accuracy: 0.7368 - val_loss: 0.9537 - val_accuracy: 0.7615\n",
      "Epoch 2/5\n",
      "60/60 [==============================] - 291s 5s/step - loss: 0.4366 - accuracy: 0.8859 - val_loss: 0.2799 - val_accuracy: 0.9268\n",
      "Epoch 3/5\n",
      "60/60 [==============================] - 571s 10s/step - loss: 0.2924 - accuracy: 0.9063 - val_loss: 0.7651 - val_accuracy: 0.8556\n",
      "Epoch 4/5\n",
      "60/60 [==============================] - 288s 5s/step - loss: 0.3366 - accuracy: 0.9042 - val_loss: 0.2995 - val_accuracy: 0.9059\n",
      "Epoch 5/5\n",
      "60/60 [==============================] - 302s 5s/step - loss: 0.2597 - accuracy: 0.9267 - val_loss: 1.0770 - val_accuracy: 0.7573\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load the pre-trained Xception model\n",
    "xception_model = Xception(weights='imagenet', include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "# Freeze the layers in the pre-trained model except the last few layers\n",
    "for layer in xception_model.layers[:-10]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add your own classification layers\n",
    "x = Flatten()(xception_model.output)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Create the new model\n",
    "model = Model(inputs=xception_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow(x_train_new, y_train_new, batch_size=32)\n",
    "validation_generator = validation_datagen.flow(x_test_new, y_test_new, batch_size=32)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=5,\n",
    "    validation_data=validation_generator\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save(\"Models/xception_finetuned.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96850397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4d479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# # Apply image sharpening\n",
    "# kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]]) # define a sharpening kernel\n",
    "# sharpened_train = np.zeros_like(x_train) # create an empty array to store the sharpened images\n",
    "# for i in range(x_train.shape[0]):\n",
    "#     img = x_train[i]\n",
    "#     sharpened = cv2.filter2D(img, -1, kernel)\n",
    "#     sharpened_train[i] = sharpened\n",
    "\n",
    "# # Apply histogram equalization\n",
    "# equalized_train = np.zeros_like(sharpened_train) # create an empty array to store the equalized images\n",
    "# for i in range(sharpened_train.shape[0]):\n",
    "#     img = sharpened_train[i]\n",
    "#     img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "#     img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])\n",
    "#     equalized = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)\n",
    "#     equalized_train[i] = equalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "46f7c592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define the sharpening kernel\n",
    "kernel = np.array([[-1,-1,-1],[-1,9,-1],[-1,-1,-1]])\n",
    "\n",
    "# Apply histogram equalization and sharpening to x_train_new\n",
    "for i in range(len(x_train_new)):\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(x_train_new[i], cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply histogram equalization\n",
    "    equalized = cv2.equalizeHist(gray)\n",
    "    \n",
    "    # Apply sharpening\n",
    "    sharpened = cv2.filter2D(equalized, -1, kernel)\n",
    "    \n",
    "    # Convert back to BGR color space\n",
    "    x_train_new[i] = cv2.cvtColor(sharpened, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "# Apply histogram equalization and sharpening to x_test_new\n",
    "for i in range(len(x_test_new)):\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(x_test_new[i], cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply histogram equalization\n",
    "    equalized = cv2.equalizeHist(gray)\n",
    "    \n",
    "    # Apply sharpening\n",
    "    sharpened = cv2.filter2D(equalized, -1, kernel)\n",
    "    \n",
    "    # Convert back to BGR color space\n",
    "    x_test_new[i] = cv2.cvtColor(sharpened, cv2.COLOR_GRAY2BGR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f81bbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load the pre-trained ResNet50 model\n",
    "resnet_model = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "# Freeze the layers in the pre-trained model\n",
    "for layer in resnet_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add your own classification layers\n",
    "x = Flatten()(resnet_model.output)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Create the new model\n",
    "model = Model(inputs=resnet_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model with a lower learning rate\n",
    "opt = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model with validation data\n",
    "history = model.fit(x_train_new, y_train_new, epochs=6, batch_size=32, validation_data=(x_test_new, y_test_new))\n",
    "\n",
    "# Save the model\n",
    "model.save(\"Models/resnet50_tl.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b6032e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[172, 152,  81],\n",
       "        [170, 154,  79],\n",
       "        [168, 156,  80],\n",
       "        ...,\n",
       "        [133,  95,  46],\n",
       "        [135,  94,  38],\n",
       "        [165, 123,  63]],\n",
       "\n",
       "       [[155, 140,  71],\n",
       "        [171, 159,  87],\n",
       "        [176, 170,  94],\n",
       "        ...,\n",
       "        [130,  92,  43],\n",
       "        [142, 103,  44],\n",
       "        [168, 128,  66]],\n",
       "\n",
       "       [[148, 143,  77],\n",
       "        [137, 134,  65],\n",
       "        [134, 137,  66],\n",
       "        ...,\n",
       "        [131,  91,  40],\n",
       "        [142, 106,  44],\n",
       "        [160, 125,  59]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[173, 152,  97],\n",
       "        [217, 198, 155],\n",
       "        [156, 146, 121],\n",
       "        ...,\n",
       "        [ 70,  74,  57],\n",
       "        [ 84,  88,  71],\n",
       "        [ 67,  74,  56]],\n",
       "\n",
       "       [[193, 165, 115],\n",
       "        [221, 196, 155],\n",
       "        [232, 211, 190],\n",
       "        ...,\n",
       "        [ 55,  58,  39],\n",
       "        [ 67,  69,  48],\n",
       "        [ 58,  60,  38]],\n",
       "\n",
       "       [[207, 177, 127],\n",
       "        [228, 200, 160],\n",
       "        [243, 218, 198],\n",
       "        ...,\n",
       "        [ 62,  65,  46],\n",
       "        [ 70,  69,  48],\n",
       "        [ 68,  68,  44]]], dtype=uint8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6a31b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
