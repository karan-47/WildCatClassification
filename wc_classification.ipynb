{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4709a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "448cc898",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = sorted(os.listdir(\"train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4f8ce85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AFRICAN LEOPARD',\n",
       " 'CARACAL',\n",
       " 'CHEETAH',\n",
       " 'CLOUDED LEOPARD',\n",
       " 'JAGUAR',\n",
       " 'LIONS',\n",
       " 'OCELOT',\n",
       " 'PUMA',\n",
       " 'SNOW LEOPARD',\n",
       " 'TIGER']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f94852ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    class_dir = os.path.join(\"train\", class_name)\n",
    "    for filename in os.listdir(class_dir):\n",
    "        # Load the image and convert it to a numpy array\n",
    "        img = cv2.imread(os.path.join(class_dir, filename))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_array = np.array(img)\n",
    "\n",
    "        # Append the numpy array to x_train\n",
    "        x_train.append(img_array)\n",
    "\n",
    "        # Append the corresponding label to y_train\n",
    "        y_train.append(i)\n",
    "\n",
    "# Convert x_train and y_train to numpy arrays\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67069af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fef93e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {i: class_names[i] for i in range(len(class_names))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b89b5437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0db62762",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = []\n",
    "y_val = []\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    class_dir = os.path.join(\"valid\", class_name)\n",
    "    for filename in os.listdir(class_dir):\n",
    "        # Load the image and convert it to a numpy array\n",
    "        img = cv2.imread(os.path.join(class_dir, filename))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_array = np.array(img)\n",
    "\n",
    "        # Append the numpy array to x_train\n",
    "        x_val.append(img_array)\n",
    "\n",
    "        # Append the corresponding label to y_train\n",
    "        y_val.append(i)\n",
    "\n",
    "# Convert x_train and y_train to numpy arrays\n",
    "x_val = np.array(x_val)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ce8ccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = to_categorical(y_val, num_classes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "299ac629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train_new: (1911, 224, 224, 3)\n",
      "Shape of y_train_new: (1911, 10)\n",
      "Shape of x_test_new: (478, 224, 224, 3)\n",
      "Shape of y_test_new: (478, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Concatenate the x and y arrays\n",
    "x_all = np.concatenate([x_train, x_val], axis=0)\n",
    "y_all = np.concatenate([y_train, y_val], axis=0)\n",
    "\n",
    "# Create a StratifiedShuffleSplit object\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use the StratifiedShuffleSplit object to split the data\n",
    "train_indices, test_indices = next(sss.split(x_all, y_all))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train_new, x_test_new = x_all[train_indices], x_all[test_indices]\n",
    "y_train_new, y_test_new = y_all[train_indices], y_all[test_indices]\n",
    "\n",
    "# Verify the shapes of the new arrays\n",
    "print(f'Shape of x_train_new: {x_train_new.shape}')\n",
    "print(f'Shape of y_train_new: {y_train_new.shape}')\n",
    "print(f'Shape of x_test_new: {x_test_new.shape}')\n",
    "print(f'Shape of y_test_new: {y_test_new.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "40c160a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60/60 [==============================] - 365s 6s/step - loss: 14.5336 - accuracy: 0.6033 - val_loss: 4.1302 - val_accuracy: 0.7448\n",
      "Epoch 2/10\n",
      "60/60 [==============================] - 395s 7s/step - loss: 1.2534 - accuracy: 0.8943 - val_loss: 3.1559 - val_accuracy: 0.7887\n",
      "Epoch 3/10\n",
      "60/60 [==============================] - 397s 7s/step - loss: 0.4695 - accuracy: 0.9560 - val_loss: 3.6325 - val_accuracy: 0.7720\n",
      "Epoch 4/10\n",
      "60/60 [==============================] - 404s 7s/step - loss: 0.2158 - accuracy: 0.9744 - val_loss: 3.3122 - val_accuracy: 0.7887\n",
      "Epoch 5/10\n",
      "60/60 [==============================] - 392s 7s/step - loss: 0.2639 - accuracy: 0.9707 - val_loss: 3.2307 - val_accuracy: 0.8285\n",
      "Epoch 6/10\n",
      "60/60 [==============================] - 392s 7s/step - loss: 0.1397 - accuracy: 0.9822 - val_loss: 2.2215 - val_accuracy: 0.8640\n",
      "Epoch 7/10\n",
      "60/60 [==============================] - 392s 7s/step - loss: 0.1939 - accuracy: 0.9765 - val_loss: 3.1981 - val_accuracy: 0.8180\n",
      "Epoch 8/10\n",
      "60/60 [==============================] - 393s 7s/step - loss: 0.3692 - accuracy: 0.9738 - val_loss: 4.0850 - val_accuracy: 0.8326\n",
      "Epoch 9/10\n",
      "60/60 [==============================] - 393s 7s/step - loss: 0.2591 - accuracy: 0.9780 - val_loss: 4.4325 - val_accuracy: 0.8389\n",
      "Epoch 10/10\n",
      "60/60 [==============================] - 393s 7s/step - loss: 0.3104 - accuracy: 0.9702 - val_loss: 4.3699 - val_accuracy: 0.8159\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Load the pre-trained VGG16 model\n",
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "# Freeze the layers in the pre-trained model\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add your own classification layers\n",
    "x = Flatten()(vgg_model.output)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Create the new model\n",
    "model = Model(inputs=vgg_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train_new, y_train_new, epochs=10, batch_size=32, validation_data=(x_test_new, y_test_new))\n",
    "model.save(\"Models/base_vgg16.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "47546bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60/60 [==============================] - 396s 7s/step - loss: 17.5772 - accuracy: 0.6337 - val_loss: 3.4935 - val_accuracy: 0.7594\n",
      "Epoch 2/10\n",
      "60/60 [==============================] - 394s 7s/step - loss: 0.6574 - accuracy: 0.9246 - val_loss: 2.2084 - val_accuracy: 0.8368\n",
      "Epoch 3/10\n",
      "60/60 [==============================] - 395s 7s/step - loss: 0.2767 - accuracy: 0.9665 - val_loss: 2.4765 - val_accuracy: 0.8347\n",
      "Epoch 4/10\n",
      "60/60 [==============================] - 395s 7s/step - loss: 0.2296 - accuracy: 0.9723 - val_loss: 3.1954 - val_accuracy: 0.8201\n",
      "Epoch 5/10\n",
      "60/60 [==============================] - 396s 7s/step - loss: 0.2284 - accuracy: 0.9754 - val_loss: 2.8430 - val_accuracy: 0.8305\n",
      "Epoch 6/10\n",
      "60/60 [==============================] - 398s 7s/step - loss: 0.1156 - accuracy: 0.9838 - val_loss: 2.6585 - val_accuracy: 0.8452\n",
      "Epoch 7/10\n",
      "60/60 [==============================] - 398s 7s/step - loss: 0.0590 - accuracy: 0.9906 - val_loss: 2.8106 - val_accuracy: 0.8368\n",
      "Epoch 8/10\n",
      "60/60 [==============================] - 397s 7s/step - loss: 0.0612 - accuracy: 0.9911 - val_loss: 3.2493 - val_accuracy: 0.8159\n",
      "Epoch 9/10\n",
      "60/60 [==============================] - 396s 7s/step - loss: 0.1484 - accuracy: 0.9864 - val_loss: 3.0831 - val_accuracy: 0.8368\n",
      "Epoch 10/10\n",
      "60/60 [==============================] - 396s 7s/step - loss: 0.1310 - accuracy: 0.9885 - val_loss: 3.1503 - val_accuracy: 0.8347\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "y_train = np.asarray(y_train)\n",
    "y_val = np.asarray(y_val)\n",
    "# Load the pre-trained VGG16 model without the top layer\n",
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the pre-trained layers so they are not updated during training\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Define a new model that includes the VGG16 model followed by a few additional layers\n",
    "model = Sequential()\n",
    "model.add(vgg_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Fit the model with validation data\n",
    "history = model.fit(x_train_new, y_train_new, epochs=10, batch_size=32, validation_data=(x_test_new, y_test_new))\n",
    "model.save(\"Models/vgg16_tl.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96850397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4d479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# # Apply image sharpening\n",
    "# kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]]) # define a sharpening kernel\n",
    "# sharpened_train = np.zeros_like(x_train) # create an empty array to store the sharpened images\n",
    "# for i in range(x_train.shape[0]):\n",
    "#     img = x_train[i]\n",
    "#     sharpened = cv2.filter2D(img, -1, kernel)\n",
    "#     sharpened_train[i] = sharpened\n",
    "\n",
    "# # Apply histogram equalization\n",
    "# equalized_train = np.zeros_like(sharpened_train) # create an empty array to store the equalized images\n",
    "# for i in range(sharpened_train.shape[0]):\n",
    "#     img = sharpened_train[i]\n",
    "#     img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "#     img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])\n",
    "#     equalized = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)\n",
    "#     equalized_train[i] = equalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46f7c592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define the sharpening kernel\n",
    "kernel = np.array([[-1,-1,-1],[-1,9,-1],[-1,-1,-1]])\n",
    "\n",
    "# Apply histogram equalization and sharpening to x_train_new\n",
    "for i in range(len(x_train_new)):\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(x_train_new[i], cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply histogram equalization\n",
    "    equalized = cv2.equalizeHist(gray)\n",
    "    \n",
    "    # Apply sharpening\n",
    "    sharpened = cv2.filter2D(equalized, -1, kernel)\n",
    "    \n",
    "    # Convert back to BGR color space\n",
    "    x_train_new[i] = cv2.cvtColor(sharpened, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "# Apply histogram equalization and sharpening to x_test_new\n",
    "for i in range(len(x_test_new)):\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(x_test_new[i], cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply histogram equalization\n",
    "    equalized = cv2.equalizeHist(gray)\n",
    "    \n",
    "    # Apply sharpening\n",
    "    sharpened = cv2.filter2D(equalized, -1, kernel)\n",
    "    \n",
    "    # Convert back to BGR color space\n",
    "    x_test_new[i] = cv2.cvtColor(sharpened, cv2.COLOR_GRAY2BGR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f81bbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60/60 [==============================] - 405s 7s/step - loss: 22.1060 - accuracy: 0.3339 - val_loss: 1.9463 - val_accuracy: 0.2908\n",
      "Epoch 2/10\n",
      "60/60 [==============================] - 404s 7s/step - loss: 1.2534 - accuracy: 0.5824 - val_loss: 1.6595 - val_accuracy: 0.4812\n",
      "Epoch 3/10\n",
      "60/60 [==============================] - 401s 7s/step - loss: 0.7053 - accuracy: 0.7666 - val_loss: 1.7185 - val_accuracy: 0.5481\n",
      "Epoch 4/10\n",
      "60/60 [==============================] - 395s 7s/step - loss: 0.4485 - accuracy: 0.8482 - val_loss: 1.5503 - val_accuracy: 0.6151\n",
      "Epoch 5/10\n",
      "60/60 [==============================] - 395s 7s/step - loss: 0.2783 - accuracy: 0.9131 - val_loss: 1.6622 - val_accuracy: 0.6109\n",
      "Epoch 6/10\n",
      "60/60 [==============================] - 396s 7s/step - loss: 0.1476 - accuracy: 0.9597 - val_loss: 1.7181 - val_accuracy: 0.6339\n",
      "Epoch 7/10\n",
      "60/60 [==============================] - 396s 7s/step - loss: 0.0906 - accuracy: 0.9712 - val_loss: 1.8960 - val_accuracy: 0.6172\n",
      "Epoch 8/10\n",
      "60/60 [==============================] - 397s 7s/step - loss: 0.0687 - accuracy: 0.9848 - val_loss: 1.9062 - val_accuracy: 0.6402\n",
      "Epoch 9/10\n",
      "60/60 [==============================] - 398s 7s/step - loss: 0.0466 - accuracy: 0.9880 - val_loss: 2.0831 - val_accuracy: 0.6339\n",
      "Epoch 10/10\n",
      "60/60 [==============================] - 396s 7s/step - loss: 0.0356 - accuracy: 0.9901 - val_loss: 2.3186 - val_accuracy: 0.6464\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "y_train = np.asarray(y_train)\n",
    "y_val = np.asarray(y_val)\n",
    "# Load the pre-trained VGG16 model without the top layer\n",
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the pre-trained layers so they are not updated during training\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Define a new model that includes the VGG16 model followed by a few additional layers\n",
    "model = Sequential()\n",
    "model.add(vgg_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Fit the model with validation data\n",
    "history = model.fit(x_train_new, y_train_new, epochs=10, batch_size=32, validation_data=(x_test_new, y_test_new))\n",
    "model.save(\"Models/enhanced_vgg16_tl.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b6032e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[172, 152,  81],\n",
       "        [170, 154,  79],\n",
       "        [168, 156,  80],\n",
       "        ...,\n",
       "        [133,  95,  46],\n",
       "        [135,  94,  38],\n",
       "        [165, 123,  63]],\n",
       "\n",
       "       [[155, 140,  71],\n",
       "        [171, 159,  87],\n",
       "        [176, 170,  94],\n",
       "        ...,\n",
       "        [130,  92,  43],\n",
       "        [142, 103,  44],\n",
       "        [168, 128,  66]],\n",
       "\n",
       "       [[148, 143,  77],\n",
       "        [137, 134,  65],\n",
       "        [134, 137,  66],\n",
       "        ...,\n",
       "        [131,  91,  40],\n",
       "        [142, 106,  44],\n",
       "        [160, 125,  59]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[173, 152,  97],\n",
       "        [217, 198, 155],\n",
       "        [156, 146, 121],\n",
       "        ...,\n",
       "        [ 70,  74,  57],\n",
       "        [ 84,  88,  71],\n",
       "        [ 67,  74,  56]],\n",
       "\n",
       "       [[193, 165, 115],\n",
       "        [221, 196, 155],\n",
       "        [232, 211, 190],\n",
       "        ...,\n",
       "        [ 55,  58,  39],\n",
       "        [ 67,  69,  48],\n",
       "        [ 58,  60,  38]],\n",
       "\n",
       "       [[207, 177, 127],\n",
       "        [228, 200, 160],\n",
       "        [243, 218, 198],\n",
       "        ...,\n",
       "        [ 62,  65,  46],\n",
       "        [ 70,  69,  48],\n",
       "        [ 68,  68,  44]]], dtype=uint8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd6c41a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
